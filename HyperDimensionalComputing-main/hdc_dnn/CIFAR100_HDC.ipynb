{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c05115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwi3/iwi3083h/.local/lib/python3.8/site-packages/skcuda/cublas.py:284: UserWarning: creating CUBLAS context to get version number\n",
      "  warnings.warn('creating CUBLAS context to get version number')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import openhd as hd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d8a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Grayscale\n",
    "from torchvision.transforms import ColorJitter\n",
    "train_data = datasets.CIFAR100(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = transforms.Compose([Grayscale(), ToTensor(), ColorJitter()]), \n",
    "    download = False,            \n",
    ")\n",
    "test_data = datasets.CIFAR100(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = transforms.Compose([Grayscale(), ToTensor(), ColorJitter()]), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ea88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.openhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07074b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = 10\n",
    "D = 20000\n",
    "hd.init(D=D, context=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c993581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aaeb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def create_random_bases():\n",
    "    position_base = hd.draw_random_hypervector()\n",
    "    intensity_base = hd.draw_random_hypervector()\n",
    "    return position_base, intensity_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d507d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def create_position_intensity_hvs(n_position, n_intensity, position_base, intensity_base):\n",
    "    position_hvs = hd.hypermatrix(n_position)\n",
    "    for i in range(n_position):\n",
    "        position_hvs[i] = hd.permute(position_base, i)\n",
    " \n",
    "    intensity_hvs = hd.hypermatrix(n_intensity)\n",
    "    for i in range(n_intensity):\n",
    "        intensity_hvs[i] = hd.permute(intensity_base, i)\n",
    "    \n",
    "    return position_hvs, intensity_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68cf62f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [__ARG__position_base : __one__]\n",
      "  <class '_ast.Assign'> :  [__ARG__intensity_base : __one__]\n",
      "\n",
      "\u001b[0m{'position_base': 'hypervec_type', 'intensity_base': 'hypervec_type', '__ARG__intensity_base': 'float*', '__ARG__position_base': 'float*', 'position_base_a9855c0b': <class 'float'>, 'intensity_base_0ab25fc2': <class 'float'>}\n",
      "Base hypervectors\t0.20672154426574707\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Base hypervectors\"):\n",
    "    position_base, intensity_base = create_random_bases()\n",
    "#     image_hv = hd.hypervector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a34e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: n_position>\n",
      "    <class '_ast.Assign'> :  [__ARG__position_hvs : __ARG__position_base]\n",
      "\n",
      "\u001b[0m{'i': <class 'int'>, 'n_position': <class 'int'>, 'position_hvs': 'hypermat_type', 'position_base': 'hypervec_type', '__ARG__position_hvs': 'float*', '__ARG__position_base': 'float*', 'position_base_i_9b8342e3': <class 'float'>, 'position_hvs_i_e80d2a15': <class 'float'>}\n",
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: n_intensity>\n",
      "    <class '_ast.Assign'> :  [__ARG__intensity_hvs : __ARG__intensity_base]\n",
      "\n",
      "\u001b[0m{'i': <class 'int'>, 'n_intensity': <class 'int'>, 'intensity_hvs': 'hypermat_type', 'intensity_base': 'hypervec_type', '__ARG__intensity_hvs': 'float*', '__ARG__intensity_base': 'float*', 'intensity_base_i_bc9447b8': <class 'float'>, 'intensity_hvs_i_cb818caa': <class 'float'>}\n",
      "Feature hypervectors\t0.33166956901550293\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Feature hypervectors\"):\n",
    "    position_hvs, intensity_hvs = create_position_intensity_hvs(1024, 255, position_base, intensity_base)\n",
    "#     image_hv = hd.hypervector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eeec20f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 20000), (255, 20000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_hvs.to_numpy().shape, intensity_hvs.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd443dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pixels(flattened_image, output_hypervector,\n",
    "                  position_hvs, intensity_hvs, n_position = 1024, n_intensity = 255): # arguments passed by args\n",
    "    for pixel_idx in range(1024):\n",
    "        output_hypervector += position_hvs[pixel_idx] * intensity_hvs[flattened_image[pixel_idx]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b13b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipolarize(arr):\n",
    "    result = np.where(arr < 0, -1, np.where(arr > 0, 1, np.random.choice([-1, 1])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514e07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(labels, pred_labels):\n",
    "    n_correct = (pred_labels == labels).sum()\n",
    "    n_labels = len(labels)\n",
    "    print(n_correct, n_labels, n_correct / float(n_labels) * 100)\n",
    "    return  n_correct / float(n_labels) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900654e",
   "metadata": {},
   "source": [
    "# Epoch Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfaea0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def retrain(class_hvs, hv_matrix, labels, N):\n",
    "    for idx in range(N): # Iterate through each image\n",
    "        class_hvs[labels[idx]] += hv_matrix[idx]\n",
    "    return class_hvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "272761b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 9876\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=True, \n",
    "                         num_workers=1)\n",
    "test_loader = DataLoader(test_data, \n",
    "                         batch_size=50,\n",
    "                         shuffle=True, \n",
    "                         num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58da8c",
   "metadata": {},
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b542cf38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [output_hypervector___base_n_____n___2964e176 : __ARG__output_hypervector]\n",
      "  <class '_ast.For'> : \n",
      "    OVERRIDING :  [output_hypervector___base_n_____n___2964e176 : __floatdmt__]\n",
      "  <class '_ast.Assign'> :  [__ARG__output_hypervector : output_hypervector___base_n_____n___2964e176]\n",
      "\n",
      "\u001b[0m{'__n__': <class 'int'>, '__blockIdx_y__': <class 'int'>, '__base_n__': 'int', '__N__': <class 'int'>, '__blockDim_x__': <class 'int'>, '__F__': <class 'int'>, '__threadIdx_x__': <class 'int'>, 'F_PER_THREAD': <class 'int'>, 'sample_idx_in_stream': <class 'int'>, '__stream__': 'int', '__M__': <class 'int'>, '__f__': <class 'int'>, '__f_idx__': <class 'int'>, 'original_feature': <class 'float'>, 'flattened_image': 'np_float_array_type', 'preprocessed_feature': <class 'float'>, '__shared_features__': 'np_float_array_type', '__d__': <class 'int'>, '__blockIdx_x__': <class 'int'>, '__D__': <class 'int'>, 'pixel_idx': <class 'int'>, 'output_hypervector': 'hypermat_type', 'position_hvs': 'hypermat_type', 'intensity_hvs': 'hypermat_type', '__ARG__position_hvs': 'float*', '__ARG__output_hypervector': 'float*', '__ARG__intensity_hvs': 'float*', 'position_hvs_pixel_idx_a06f5629': <class 'float'>, '__shared_features___pixel_idx_9c0efb6a': <class 'float'>, 'intensity_hvs_pixel_idx___shared_features___b25a98f3': <class 'float'>, 'output_hypervector___base_n_____n___2964e176': <class 'float'>, 'flattened_image___f_idx___sample_idx_in_stream_6d55cc3f': <class 'float'>, '__shared_features_____f_idx___112c42af': <class 'float'>}\n",
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: N>\n",
      "    <class '_ast.Assign'> :  [__ARG__class_hvs : __ARG__class_hvs + __ARG__hv_matrix]\n",
      "\n",
      "\u001b[0m{'idx': <class 'int'>, 'N': <class 'int'>, 'class_hvs': 'hypermat_type', 'labels': 'np_int_array_type', 'hv_matrix': 'hypermat_type', '__ARG__labels': 'int*', '__ARG__labels__STRIDE__': 'const int', '__ARG__hv_matrix': 'float*', '__ARG__class_hvs': 'float*', 'hv_matrix_idx_ead026f6': <class 'float'>, 'labels_idx_b9c77ce4': <class 'int'>, 'class_hvs_labels_idx_df62a0b1': <class 'float'>}\n",
      "9818 9876 99.41271769947348\n",
      "At epoch  0 :  99.41271769947348\n",
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: N>\n",
      "    <class '_ast.Assign'> :  [__ARG__class_hvs : __ARG__class_hvs + __ARG__hv_matrix]\n",
      "\n",
      "\u001b[0m{'idx': <class 'int'>, 'N': <class 'int'>, 'class_hvs': 'hypermat_type', 'labels': 'np_int_array_type', 'hv_matrix': 'hypermat_type', '__ARG__labels': 'int*', '__ARG__labels__STRIDE__': 'const int', '__ARG__hv_matrix': 'float*', '__ARG__class_hvs': 'float*', 'hv_matrix_idx_ead026f6': <class 'float'>, 'labels_idx_b9c77ce4': <class 'int'>, 'class_hvs_labels_idx_df62a0b1': <class 'float'>}\n",
      "9815 9876 99.38234102875658\n",
      "At epoch  1 :  99.38234102875658\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "n_classes = 100\n",
    "class_hvs = hd.hypermatrix(n_classes)\n",
    "train_performances = []\n",
    "for e in range(EPOCHS):\n",
    "    # Fetch Current Image batch\n",
    "    images, labels = next(iter(train_loader))\n",
    "    images = images.reshape(images.shape[0], images.shape[1]*images.shape[2]*images.shape[3]) * 255\n",
    "    labels = np.array(labels, dtype = np.int32)\n",
    "    # Encode the images of this batch\n",
    "    hv_matrix = hd.encode(\n",
    "            encode_pixels, extra_args = (position_hvs, intensity_hvs, 1024, 255),\n",
    "            feature_matrix = images\n",
    "            )\n",
    "    # bipolarize\n",
    "    hv_numpy = hv_matrix.to_numpy()\n",
    "    hv_numpy = bipolarize(hv_numpy)\n",
    "    hv_matrix = hv_matrix.from_numpy(hv_numpy)\n",
    "    # add to class_hvs\n",
    "    class_hvs = retrain(class_hvs, hv_matrix, labels, BATCH_SIZE)\n",
    "    # bipolarize\n",
    "    class_hvs_np = class_hvs.to_numpy()\n",
    "    class_hvs_np = bipolarize(class_hvs_np)\n",
    "    class_hvs = class_hvs.from_numpy(class_hvs_np)\n",
    "    v = validate(labels, hd.search(class_hvs, hv_matrix).to_numpy())\n",
    "    train_performances.append(v)\n",
    "    print(\"At epoch \",e, \": \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7d143",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a611eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_tst, labels_tst = next(iter(test_loader))\n",
    "images_tst = images_tst.reshape(images_tst.shape[0], images_tst.shape[1]*images_tst.shape[2]*images_tst.shape[3]) * 255\n",
    "labels_tst = np.array(labels_tst, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08f47453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [output_hypervector___base_n_____n___2964e176 : __ARG__output_hypervector]\n",
      "  <class '_ast.For'> : \n",
      "    OVERRIDING :  [output_hypervector___base_n_____n___2964e176 : __floatdmt__]\n",
      "  <class '_ast.Assign'> :  [__ARG__output_hypervector : output_hypervector___base_n_____n___2964e176]\n",
      "\n",
      "\u001b[0m{'__n__': <class 'int'>, '__blockIdx_y__': <class 'int'>, '__base_n__': 'int', '__N__': <class 'int'>, '__blockDim_x__': <class 'int'>, '__F__': <class 'int'>, '__threadIdx_x__': <class 'int'>, 'F_PER_THREAD': <class 'int'>, 'sample_idx_in_stream': <class 'int'>, '__stream__': 'int', '__M__': <class 'int'>, '__f__': <class 'int'>, '__f_idx__': <class 'int'>, 'original_feature': <class 'float'>, 'flattened_image': 'np_float_array_type', 'preprocessed_feature': <class 'float'>, '__shared_features__': 'np_float_array_type', '__d__': <class 'int'>, '__blockIdx_x__': <class 'int'>, '__D__': <class 'int'>, 'pixel_idx': <class 'int'>, 'output_hypervector': 'hypermat_type', 'position_hvs': 'hypermat_type', 'intensity_hvs': 'hypermat_type', '__ARG__position_hvs': 'float*', '__ARG__output_hypervector': 'float*', '__ARG__intensity_hvs': 'float*', 'position_hvs_pixel_idx_a06f5629': <class 'float'>, '__shared_features___pixel_idx_9c0efb6a': <class 'float'>, 'intensity_hvs_pixel_idx___shared_features___b25a98f3': <class 'float'>, 'output_hypervector___base_n_____n___2964e176': <class 'float'>, 'flattened_image___f_idx___sample_idx_in_stream_6d55cc3f': <class 'float'>, '__shared_features_____f_idx___112c42af': <class 'float'>}\n",
      "Encode Test\t0.5609443187713623\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Encode Test\"):\n",
    "    hv_matrix_tst = hd.encode(\n",
    "            encode_pixels, extra_args = (position_hvs, intensity_hvs, 1024, 255),\n",
    "            feature_matrix = images_tst\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7f8e7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv_numpy_tst = hv_matrix_tst.to_numpy()\n",
    "hv_numpy_tst = bipolarize(hv_numpy_tst)\n",
    "hv_matrix_tst = hv_matrix_tst.from_numpy(hv_numpy_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db341e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Run Time\t0.13425493240356445\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Test Run Time\"):\n",
    "    hd.search(class_hvs, hv_matrix_tst).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a8cc803",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 4.0\n",
      "On Test Data 4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"On Test Data\", validate(labels_tst, hd.search(class_hvs, hv_matrix_tst).to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cefbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"On Train Data\", validate(labels, hd.search(class_hvs, hv_matrix).to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape((9876, 32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8445318",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_labels = hd.search(class_hvs, hv_matrix).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fe450",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tst = images_tst.reshape((50, 32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ff06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tst[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4241bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_tst[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d895e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(len(train_performances)), train_performances)\n",
    "# plt.savefig(\"Training_performances_CIFAR100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad5f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d348b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "681e445e",
   "metadata": {},
   "source": [
    "# Guided Training\n",
    "### Only update the class vectors which are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def guided_retrain(class_hvs, hv_matrix, labels, N):\n",
    "    search_results = hd.search(class_hvs, hv_matrix)\n",
    "\n",
    "    for idx in range(N):\n",
    "        if search_results[idx] != labels[idx]:\n",
    "            class_hvs[labels[idx]] += hv_matrix[idx]\n",
    "            class_hvs[search_results[idx]] -= hv_matrix[idx]\n",
    "\n",
    "    return class_hvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283508b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 2000\n",
    "n_classes = 10\n",
    "class_hvs = hd.hypermatrix(n_classes)\n",
    "train_performances = []\n",
    "# Fetch Current Image batch\n",
    "images, labels = next(iter(train_loader))\n",
    "images = images.reshape(images.shape[0], images.shape[1]*images.shape[2]*images.shape[3]) * 255\n",
    "labels = np.array(labels, dtype = np.int32)\n",
    "# Encode the images of this batch\n",
    "hv_matrix = hd.encode(\n",
    "        encode_pixels, extra_args = (position_hvs, intensity_hvs, 784, 255),\n",
    "        feature_matrix = images\n",
    "        )\n",
    "# bipolarize\n",
    "hv_numpy = hv_matrix.to_numpy()\n",
    "hv_numpy = bipolarize(hv_numpy)\n",
    "hv_matrix = hv_matrix.from_numpy(hv_numpy)\n",
    "for e in range(ITERS):\n",
    "    # add to class_hvs\n",
    "    class_hvs = guided_retrain(class_hvs, hv_matrix, labels, BATCH_SIZE)\n",
    "    # bipolarize\n",
    "    class_hvs_np = class_hvs.to_numpy()\n",
    "    class_hvs_np = bipolarize(class_hvs_np)\n",
    "    class_hvs = class_hvs.from_numpy(class_hvs_np)\n",
    "    v = validate(labels, hd.search(class_hvs, hv_matrix).to_numpy())\n",
    "    train_performances.append(v)\n",
    "    print(\"At epoch \",e, \": \", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"On Test Data\", validate(labels, hd.search(class_hvs, hv_matrix).to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33268f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
