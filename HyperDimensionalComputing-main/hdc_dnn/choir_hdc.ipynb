{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwi3/iwi3083h/.local/lib/python3.8/site-packages/skcuda/cublas.py:284: UserWarning: creating CUBLAS context to get version number\n",
      "  warnings.warn('creating CUBLAS context to get version number')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import struct\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import openhd as hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.openhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 10\n",
    "D = 10000\n",
    "hd.init(D=D, context=globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"/home/hpc/iwi3/iwi3083h/openhd/examples/dataset/isolet_train.choir_dat\"\n",
    "test_filename = \"/home/hpc/iwi3/iwi3083h/openhd/examples/dataset/isolet_test.choir_dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, labels, n_classes = hd.utils.read_choir_dat(train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1, ..., 23, 24, 25], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6238, 617)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_tst, labels_tst, n_classes_tst = hd.utils.read_choir_dat(test_filename)\n",
    "\n",
    "feature_matrix, feature_matrix_tst = \\\n",
    "        hd.utils.MatrixNormalizer().norm_two(\n",
    "                feature_matrix, feature_matrix_tst)\n",
    "N_tst = feature_matrix_tst.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6238, 617)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = feature_matrix.shape[0]\n",
    "F = feature_matrix.shape[1]\n",
    "N, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def create_random_bases():\n",
    "    id_base = hd.draw_random_hypervector()\n",
    "    level_base = hd.draw_random_hypervector()\n",
    "    return id_base, level_base\n",
    "\n",
    "\n",
    "@hd.run\n",
    "def create_ids(F, id_base):\n",
    "    id_hvs = hd.hypermatrix(F) # np.zeros(F, N) (not the empty list) \n",
    "    for f in range(F):\n",
    "        id_hvs[f] = hd.permute(id_base, f)\n",
    "\n",
    "    return id_hvs\n",
    "\n",
    "@hd.run\n",
    "def create_levels(Q, level_base):\n",
    "    level_hvs = hd.hypermatrix(Q+1) # np.zeros((Q+1), N) (not the empty list)\n",
    "    for q in range(Q+1):\n",
    "        idx = int(q/float(Q) * D) / 2\n",
    "        level_hvs[q] = hd.flip(level_base, idx)\n",
    "        level_hvs[q] = hd.shuffle(level_hvs[q], 0)\n",
    "\n",
    "    return level_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [__ARG__id_base : __one__]\n",
      "  <class '_ast.Assign'> :  [__ARG__level_base : __one__]\n",
      "\n",
      "\u001b[0m{'id_base': 'hypervec_type', 'level_base': 'hypervec_type', '__ARG__id_base': 'float*', '__ARG__level_base': 'float*', 'id_base_22b19319': <class 'float'>, 'level_base_5541502b': <class 'float'>}\n",
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: F>\n",
      "    <class '_ast.Assign'> :  [__ARG__id_hvs : __ARG__id_base]\n",
      "\n",
      "\u001b[0m{'f': <class 'int'>, 'F': <class 'int'>, 'id_hvs': 'hypermat_type', 'id_base': 'hypervec_type', '__ARG__id_base': 'float*', '__ARG__id_hvs': 'float*', 'id_base_f_16a56737': <class 'float'>, 'id_hvs_f_00177a23': <class 'float'>}\n",
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [level_hvs_q_7acb546c : __ARG__level_base]\n",
      "  <class '_ast.Assign'> :  [__ARG__level_hvs : level_hvs_q_7acb546c]\n",
      "\n",
      "\u001b[0m{'idx': <class 'int'>, 'q': 'int', 'Q': <class 'int'>, 'D': <class 'int'>, 'level_hvs': 'hypermat_type', 'level_base': 'hypervec_type', '__ARG__level_hvs': 'float*', '__ARG__level_base': 'float*', 'level_base_5541502b': <class 'float'>, 'level_hvs_q_7acb546c': <class 'float'>}\n",
      "Base hypervectors\t1.2799313068389893\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Base hypervectors\"):\n",
    "    id_base, level_base = create_random_bases()\n",
    "    id_hvs = create_ids(F, id_base)\n",
    "    level_hvs = create_levels(Q, level_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesser(\n",
    "        org_feature, cnv_feature, # Predefined argument (single feature)\n",
    "        Q, level_hvs, id_hvs): # arguments passed by args\n",
    "    cnv_feature = int(org_feature * Q)\n",
    "\n",
    "\n",
    "def encoder(\n",
    "        input_features, output_hypervector, # Predefined arguments\n",
    "        Q, level_hvs, id_hvs): # arguments passed by args\n",
    "    for f in range(F):\n",
    "        output_hypervector += level_hvs[input_features[f]] * id_hvs[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [output_hypervector___n_____base_n___2964e176 : __ARG__output_hypervector]\n",
      "  <class '_ast.For'> :  <RPT: F>\n",
      "    <class '_ast.Assign'> :  [output_hypervector___n_____base_n___2964e176 : __ARG__id_hvs*__ARG__level_hvs + output_hypervector___n_____base_n___2964e176]\n",
      "  <class '_ast.Assign'> :  [__ARG__output_hypervector : output_hypervector___n_____base_n___2964e176]\n",
      "\n",
      "\u001b[0m{'__n__': <class 'int'>, '__blockIdx_y__': <class 'int'>, '__base_n__': 'int', '__N__': <class 'int'>, '__blockDim_x__': <class 'int'>, '__F__': <class 'int'>, '__threadIdx_x__': <class 'int'>, 'F_PER_THREAD': <class 'int'>, 'sample_idx_in_stream': <class 'int'>, '__stream__': 'int', '__M__': <class 'int'>, '__f__': <class 'int'>, '__f_idx__': <class 'int'>, 'org_feature': <class 'float'>, 'input_features': 'np_float_array_type', 'cnv_feature': <class 'int'>, 'Q': <class 'int'>, '__shared_features__': 'np_float_array_type', '__d__': <class 'int'>, '__blockIdx_x__': <class 'int'>, '__D__': <class 'int'>, 'f': <class 'int'>, 'F': <class 'int'>, 'output_hypervector': 'hypermat_type', 'level_hvs': 'hypermat_type', 'id_hvs': 'hypermat_type', '__ARG__output_hypervector': 'float*', '__ARG__level_hvs': 'float*', '__ARG__id_hvs': 'float*', '__shared_features___f_fb10dfcf': <class 'float'>, 'level_hvs___shared_features___f_7add4eda': <class 'float'>, 'id_hvs_f_00177a23': <class 'float'>, 'output_hypervector___n_____base_n___2964e176': <class 'float'>, 'input_features___f_idx___sample_idx_in_stream_dc384242': <class 'float'>, '__shared_features_____f_idx___112c42af': <class 'float'>}\n",
      "Encode training\t0.751380443572998\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Encode training\"):\n",
    "    hv_matrix = hd.encode(\n",
    "            encoder, extra_args = (Q, level_hvs, id_hvs),\n",
    "            feature_matrix = feature_matrix,\n",
    "            preprocess_function = preprocesser # optional\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [output_hypervector___n_____base_n___2964e176 : __ARG__output_hypervector]\n",
      "  <class '_ast.For'> :  <RPT: F>\n",
      "    <class '_ast.Assign'> :  [output_hypervector___n_____base_n___2964e176 : __ARG__id_hvs*__ARG__level_hvs + output_hypervector___n_____base_n___2964e176]\n",
      "  <class '_ast.Assign'> :  [__ARG__output_hypervector : output_hypervector___n_____base_n___2964e176]\n",
      "\n",
      "\u001b[0m{'__n__': <class 'int'>, '__blockIdx_y__': <class 'int'>, '__base_n__': 'int', '__N__': <class 'int'>, '__blockDim_x__': <class 'int'>, '__F__': <class 'int'>, '__threadIdx_x__': <class 'int'>, 'F_PER_THREAD': <class 'int'>, 'sample_idx_in_stream': <class 'int'>, '__stream__': 'int', '__M__': <class 'int'>, '__f__': <class 'int'>, '__f_idx__': <class 'int'>, 'org_feature': <class 'float'>, 'input_features': 'np_float_array_type', 'cnv_feature': <class 'int'>, 'Q': <class 'int'>, '__shared_features__': 'np_float_array_type', '__d__': <class 'int'>, '__blockIdx_x__': <class 'int'>, '__D__': <class 'int'>, 'f': <class 'int'>, 'F': <class 'int'>, 'output_hypervector': 'hypermat_type', 'level_hvs': 'hypermat_type', 'id_hvs': 'hypermat_type', '__ARG__output_hypervector': 'float*', '__ARG__level_hvs': 'float*', '__ARG__id_hvs': 'float*', '__shared_features___f_fb10dfcf': <class 'float'>, 'level_hvs___shared_features___f_7add4eda': <class 'float'>, 'id_hvs_f_00177a23': <class 'float'>, 'output_hypervector___n_____base_n___2964e176': <class 'float'>, 'input_features___f_idx___sample_idx_in_stream_dc384242': <class 'float'>, '__shared_features_____f_idx___112c42af': <class 'float'>}\n",
      "Encode testing\t0.5922667980194092\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Encode testing\"):\n",
    "    hv_matrix_tst = hd.encode(\n",
    "            encoder, extra_args = (Q, level_hvs, id_hvs),\n",
    "            feature_matrix = feature_matrix_tst,\n",
    "            preprocess_function = preprocesser # optional\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the size for which encoding breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worked = []\n",
    "for i in range(feature_matrix_tst.shape[1], 0, -1):\n",
    "    print(i)\n",
    "    cropped_matrix = feature_matrix_tst[:2, :i]\n",
    "    worked.append(cropped_matrix.size * cropped_matrix.itemsize / (1024))# KB\n",
    "    try:\n",
    "        hv_matrix_tst = hd.encode(\n",
    "            encoder, extra_args = (Q, level_hvs, id_hvs),\n",
    "            feature_matrix = cropped_matrix,\n",
    "            preprocess_function = preprocesser # optional\n",
    "        )\n",
    "    except:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def single_pass(hv_matrix, labels, N, n_classes):\n",
    "    class_hvs = hd.hypermatrix(n_classes)\n",
    "\n",
    "    for idx in range(N):\n",
    "        class_hvs[labels[idx]] += hv_matrix[idx]\n",
    "\n",
    "    return class_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: N>\n",
      "    <class '_ast.Assign'> :  [__ARG__class_hvs : __ARG__class_hvs + __ARG__hv_matrix]\n",
      "\n",
      "\u001b[0m{'idx': <class 'int'>, 'N': <class 'int'>, 'class_hvs': 'hypermat_type', 'labels': 'np_int_array_type', 'hv_matrix': 'hypermat_type', '__ARG__hv_matrix': 'float*', '__ARG__class_hvs': 'float*', '__ARG__labels': 'int*', '__ARG__labels__STRIDE__': 'const int', 'hv_matrix_idx_ead026f6': <class 'float'>, 'labels_idx_b9c77ce4': <class 'int'>, 'class_hvs_labels_idx_df62a0b1': <class 'float'>}\n",
      "Single pass\t0.4764268398284912\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Single pass\"):\n",
    "    class_hvs = single_pass(hv_matrix, labels, N, n_classes)\n",
    "    class_hvs.debug_print_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(labels, pred_labels):\n",
    "    n_correct = (pred_labels == labels).sum()\n",
    "    n_labels = len(labels)\n",
    "    print(n_correct, n_labels, n_correct / float(n_labels) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def retrain(class_hvs, hv_matrix, labels, N, n_classes):\n",
    "    search_results = hd.search(class_hvs, hv_matrix)\n",
    "\n",
    "    for idx in range(N):\n",
    "        if search_results[idx] != labels[idx]:\n",
    "            class_hvs[labels[idx]] += hv_matrix[idx]\n",
    "            class_hvs[search_results[idx]] -= hv_matrix[idx]\n",
    "\n",
    "    return class_hvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.For'> :  <RPT: N>\n",
      "    <class '_ast.Assign'> :  [hv_matrix_idx_ead026f6 : __ARG__hv_matrix]\n",
      "    <class '_ast.If'> : \n",
      "      then : \n",
      "        <class '_ast.Assign'> :  [__ARG__class_hvs : __ARG__class_hvs + hv_matrix_idx_ead026f6]\n",
      "        <class '_ast.Assign'> :  [__ARG__class_hvs : __ARG__class_hvs + hv_matrix_idx_ead026f6]\n",
      "      else : \n",
      "\n",
      "\u001b[0m{'idx': <class 'int'>, 'N': <class 'int'>, 'search_results': 'np_int_array_type', 'labels': 'np_int_array_type', 'class_hvs': 'hypermat_type', 'hv_matrix': 'hypermat_type', '__ARG__search_results': 'int*', '__ARG__search_results__STRIDE__': 'const int', '__ARG__hv_matrix': 'float*', '__ARG__class_hvs': 'float*', '__ARG__labels': 'int*', '__ARG__labels__STRIDE__': 'const int', 'search_results_idx_b85d35f6': <class 'int'>, 'labels_idx_b9c77ce4': <class 'int'>, 'hv_matrix_idx_ead026f6': <class 'float'>, 'class_hvs_labels_idx_df62a0b1': <class 'float'>, 'class_hvs_search_results_idx_572d847d': <class 'float'>}\n",
      "Retrain itereation: 0\t0.5982990264892578\n",
      "Retrain itereation: 1\t0.10811257362365723\n",
      "Retrain itereation: 2\t0.1052401065826416\n",
      "Retrain itereation: 3\t0.10586810111999512\n",
      "Retrain itereation: 4\t0.10574936866760254\n",
      "Retrain itereation: 5\t0.10352945327758789\n",
      "Retrain itereation: 6\t0.10365915298461914\n",
      "Retrain itereation: 7\t0.10390472412109375\n",
      "Retrain itereation: 8\t0.10355973243713379\n",
      "Retrain itereation: 9\t0.10388302803039551\n",
      "Retrain itereation: 10\t0.10330080986022949\n",
      "Retrain itereation: 11\t0.10370850563049316\n",
      "Retrain itereation: 12\t0.10380077362060547\n",
      "Retrain itereation: 13\t0.10389542579650879\n",
      "Retrain itereation: 14\t0.10316181182861328\n",
      "Retrain itereation: 15\t0.10398149490356445\n",
      "Retrain itereation: 16\t0.1040334701538086\n",
      "Retrain itereation: 17\t0.10368704795837402\n",
      "Retrain itereation: 18\t0.10336637496948242\n",
      "Retrain itereation: 19\t0.10357785224914551\n",
      "Retrain itereation: 20\t0.1035163402557373\n",
      "Retrain itereation: 21\t0.10352230072021484\n",
      "Retrain itereation: 22\t0.10351204872131348\n",
      "Retrain itereation: 23\t0.10362744331359863\n",
      "Retrain itereation: 24\t0.10315966606140137\n",
      "Retrain itereation: 25\t0.10349249839782715\n",
      "Retrain itereation: 26\t0.10336971282958984\n",
      "Retrain itereation: 27\t0.10348272323608398\n",
      "Retrain itereation: 28\t0.10357379913330078\n",
      "Retrain itereation: 29\t0.10375499725341797\n",
      "Retrain itereation: 30\t0.1035757064819336\n",
      "Retrain itereation: 31\t0.10403871536254883\n",
      "Retrain itereation: 32\t0.10316109657287598\n",
      "Retrain itereation: 33\t0.10336852073669434\n",
      "Retrain itereation: 34\t0.10321426391601562\n",
      "Retrain itereation: 35\t0.10380029678344727\n",
      "Retrain itereation: 36\t0.10306668281555176\n",
      "Retrain itereation: 37\t0.10348820686340332\n",
      "Retrain itereation: 38\t0.10336422920227051\n",
      "Retrain itereation: 39\t0.10348892211914062\n",
      "Retrain itereation: 40\t0.10380887985229492\n",
      "Retrain itereation: 41\t0.10486268997192383\n",
      "Retrain itereation: 42\t0.10390019416809082\n",
      "Retrain itereation: 43\t0.10425138473510742\n",
      "Retrain itereation: 44\t0.10401153564453125\n",
      "Retrain itereation: 45\t0.10428214073181152\n",
      "Retrain itereation: 46\t0.1039738655090332\n",
      "Retrain itereation: 47\t0.10429739952087402\n",
      "Retrain itereation: 48\t0.10437417030334473\n",
      "Retrain itereation: 49\t0.10553693771362305\n",
      "Retrain itereation: 50\t0.10412192344665527\n",
      "Retrain itereation: 51\t0.10432648658752441\n",
      "Retrain itereation: 52\t0.10418581962585449\n",
      "Retrain itereation: 53\t0.10442662239074707\n",
      "Retrain itereation: 54\t0.10432004928588867\n",
      "Retrain itereation: 55\t0.10467100143432617\n",
      "Retrain itereation: 56\t0.10438728332519531\n",
      "Retrain itereation: 57\t0.10417866706848145\n",
      "Retrain itereation: 58\t0.10387969017028809\n",
      "Retrain itereation: 59\t0.10423588752746582\n",
      "Retrain itereation: 60\t0.10433197021484375\n",
      "Retrain itereation: 61\t0.1047980785369873\n",
      "Retrain itereation: 62\t0.10408496856689453\n",
      "Retrain itereation: 63\t0.1048121452331543\n",
      "Retrain itereation: 64\t0.10455894470214844\n",
      "Retrain itereation: 65\t0.1045677661895752\n",
      "Retrain itereation: 66\t0.10447144508361816\n",
      "Retrain itereation: 67\t0.10432147979736328\n",
      "Retrain itereation: 68\t0.10435247421264648\n",
      "Retrain itereation: 69\t0.10462665557861328\n",
      "Retrain itereation: 70\t0.10490560531616211\n",
      "Retrain itereation: 71\t0.10491180419921875\n",
      "Retrain itereation: 72\t0.10408473014831543\n",
      "Retrain itereation: 73\t0.10455632209777832\n",
      "Retrain itereation: 74\t0.10444831848144531\n",
      "Retrain itereation: 75\t0.10417509078979492\n",
      "Retrain itereation: 76\t0.10420918464660645\n",
      "Retrain itereation: 77\t0.10514426231384277\n",
      "Retrain itereation: 78\t0.10434341430664062\n",
      "Retrain itereation: 79\t0.10483813285827637\n",
      "Retrain itereation: 80\t0.1046147346496582\n",
      "Retrain itereation: 81\t0.10428357124328613\n",
      "Retrain itereation: 82\t0.10391569137573242\n",
      "Retrain itereation: 83\t0.10410523414611816\n",
      "Retrain itereation: 84\t0.10384488105773926\n",
      "Retrain itereation: 85\t0.10407447814941406\n",
      "Retrain itereation: 86\t0.10399675369262695\n",
      "Retrain itereation: 87\t0.10474681854248047\n",
      "Retrain itereation: 88\t0.10379290580749512\n",
      "Retrain itereation: 89\t0.10463500022888184\n",
      "Retrain itereation: 90\t0.10451483726501465\n",
      "Retrain itereation: 91\t0.10491251945495605\n",
      "Retrain itereation: 92\t0.10405516624450684\n",
      "Retrain itereation: 93\t0.10449409484863281\n",
      "Retrain itereation: 94\t0.1043539047241211\n",
      "Retrain itereation: 95\t0.10446453094482422\n",
      "Retrain itereation: 96\t0.10549235343933105\n",
      "Retrain itereation: 97\t0.10679173469543457\n",
      "Retrain itereation: 98\t0.10459709167480469\n",
      "Retrain itereation: 99\t0.10461711883544922\n"
     ]
    }
   ],
   "source": [
    "RETRAIN_ITERATIONS = 100\n",
    "SHOW_STEP_RESULT = False\n",
    "for it in range(RETRAIN_ITERATIONS):\n",
    "    with hd.utils.timing(\"Retrain itereation: %d\" % it):\n",
    "        class_hvs = retrain(class_hvs, hv_matrix, labels, N, n_classes)\n",
    "\n",
    "    if SHOW_STEP_RESULT and labels_tst is not None:\n",
    "        validate(labels_tst, hd.search(class_hvs, hv_matrix_tst).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(labels, pred_labels):\n",
    "    n_correct = (pred_labels == labels).sum()\n",
    "    n_labels = len(labels)\n",
    "    print(n_correct, n_labels, n_correct / float(n_labels) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with class model\n",
      "\t0.09038066864013672\n",
      "1452 1559 93.13662604233483\n"
     ]
    }
   ],
   "source": [
    "@hd.run\n",
    "def assoc_search(class_hvs, hv_matrix_tst):\n",
    "    ret = hd.search(class_hvs, hv_matrix_tst)\n",
    "    return ret\n",
    "\n",
    "with hd.utils.timing(\"Testing with class model\\n\"):\n",
    "    search_results = assoc_search(class_hvs, hv_matrix_tst)\n",
    "\n",
    "validate(labels_tst, search_results.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6238 6238 100.0\n"
     ]
    }
   ],
   "source": [
    "search_results = assoc_search(class_hvs, hv_matrix)\n",
    "validate(labels, search_results.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
