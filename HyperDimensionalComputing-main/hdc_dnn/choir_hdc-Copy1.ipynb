{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/iwi3/iwi3083h/.local/lib/python3.8/site-packages/skcuda/cublas.py:284: UserWarning: creating CUBLAS context to get version number\n",
      "  warnings.warn('creating CUBLAS context to get version number')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import struct\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import openhd as hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 10\n",
    "D = 10000\n",
    "hd.init(D=D, context=globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"/home/hpc/iwi3/iwi3083h/openhd/examples/dataset/isolet_train.choir_dat\"\n",
    "test_filename = \"/home/hpc/iwi3/iwi3083h/openhd/examples/dataset/isolet_test.choir_dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, labels, n_classes = hd.utils.read_choir_dat(train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1, ..., 23, 24, 25], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4394, -0.093 ,  0.1718, ...,  0.641 ,  0.5898, -0.4872],\n",
       "       [-0.4348, -0.1198,  0.2474, ...,  0.4318,  0.4546, -0.091 ],\n",
       "       [-0.233 ,  0.2124,  0.5014, ...,  0.254 ,  0.1588, -0.4762],\n",
       "       ...,\n",
       "       [-0.5824, -0.1646,  0.1406, ...,  0.6812,  0.517 ,  0.343 ],\n",
       "       [ 0.016 ,  0.8168,  1.    , ...,  0.1034, -0.1954, -0.862 ],\n",
       "       [-0.6116, -0.104 ,  0.2566, ..., -0.0536,  0.0714, -0.0892]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_tst, labels_tst, n_classes_tst = hd.utils.read_choir_dat(test_filename)\n",
    "\n",
    "feature_matrix, feature_matrix_tst = \\\n",
    "        hd.utils.MatrixNormalizer().norm_two(\n",
    "                feature_matrix, feature_matrix_tst)\n",
    "N_tst = feature_matrix_tst.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.682182312011719"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.size * feature_matrix.itemsize / (1024*1024) # MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6693687438964844"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_tst.size * feature_matrix_tst.itemsize / (1024*1024) # MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6238, 617)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = feature_matrix.shape[0]\n",
    "F = feature_matrix.shape[1]\n",
    "N, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2323836088180542"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allocated Memory\n",
    "\n",
    "(N * D * np.dtype(np.float32).itemsize) / (1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def create_random_bases():\n",
    "    id_base = hd.draw_random_hypervector()\n",
    "    level_base = hd.draw_random_hypervector()\n",
    "    return id_base, level_base\n",
    "\n",
    "\n",
    "@hd.run\n",
    "def create_ids(F, id_base):\n",
    "    id_hvs = hd.hypermatrix(F) # np.zeros(F, N) (not the empty list) \n",
    "    for f in range(F):\n",
    "        id_hvs[f] = hd.permute(id_base, f)\n",
    "\n",
    "    return id_hvs\n",
    "\n",
    "@hd.run\n",
    "def create_levels(Q, level_base):\n",
    "    level_hvs = hd.hypermatrix(Q+1) # np.zeros((Q+1), N) (not the empty list)\n",
    "    for q in range(Q+1):\n",
    "        idx = int(q/float(Q) * D) / 2\n",
    "        level_hvs[q] = hd.flip(level_base, idx)\n",
    "        level_hvs[q] = hd.shuffle(level_hvs[q], 0)\n",
    "\n",
    "    return level_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base hypervectors\t0.01959848403930664\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Base hypervectors\"):\n",
    "    id_base, level_base = create_random_bases()\n",
    "    id_hvs = create_ids(F, id_base)\n",
    "    level_hvs = create_levels(Q, level_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesser(\n",
    "        org_feature, cnv_feature, # Predefined argument (single feature)\n",
    "        Q, level_hvs, id_hvs): # arguments passed by args\n",
    "    cnv_feature = int(org_feature * Q)\n",
    "\n",
    "\n",
    "def encoder(\n",
    "        input_features, output_hypervector, # Predefined arguments\n",
    "        Q, level_hvs, id_hvs): # arguments passed by args\n",
    "    for f in range(F):\n",
    "        output_hypervector += level_hvs[input_features[f]] * id_hvs[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [output_hypervector___base_n_____n___2964e176 : __ARG__output_hypervector]\n",
      "  <class '_ast.For'> :  <RPT: F>\n",
      "    <class '_ast.Assign'> :  [output_hypervector___base_n_____n___2964e176 : __ARG__id_hvs*__ARG__level_hvs + output_hypervector___base_n_____n___2964e176]\n",
      "  <class '_ast.Assign'> :  [__ARG__output_hypervector : output_hypervector___base_n_____n___2964e176]\n",
      "\n",
      "\u001b[0m{'__n__': <class 'int'>, '__blockIdx_y__': <class 'int'>, '__base_n__': 'int', '__N__': <class 'int'>, '__blockDim_x__': <class 'int'>, '__F__': <class 'int'>, '__threadIdx_x__': <class 'int'>, 'F_PER_THREAD': <class 'int'>, 'sample_idx_in_stream': <class 'int'>, '__stream__': 'int', '__M__': <class 'int'>, '__f__': <class 'int'>, '__f_idx__': <class 'int'>, 'org_feature': <class 'float'>, 'input_features': 'np_float_array_type', 'cnv_feature': <class 'int'>, 'Q': <class 'int'>, '__shared_features__': 'np_float_array_type', '__d__': <class 'int'>, '__blockIdx_x__': <class 'int'>, '__D__': <class 'int'>, 'f': <class 'int'>, 'F': <class 'int'>, 'output_hypervector': 'hypermat_type', 'level_hvs': 'hypermat_type', 'id_hvs': 'hypermat_type', '__ARG__output_hypervector': 'float*', '__ARG__level_hvs': 'float*', '__ARG__id_hvs': 'float*', '__shared_features___f_fb10dfcf': <class 'float'>, 'level_hvs___shared_features___f_7add4eda': <class 'float'>, 'id_hvs_f_00177a23': <class 'float'>, 'output_hypervector___base_n_____n___2964e176': <class 'float'>, 'input_features_sample_idx_in_stream___f_idx___dc384242': <class 'float'>, '__shared_features_____f_idx___112c42af': <class 'float'>}\n",
      "Encode training\t0.5181751251220703\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Encode training\"):\n",
    "    hv_matrix = hd.encode(\n",
    "            encoder, extra_args = (Q, level_hvs, id_hvs),\n",
    "            feature_matrix = feature_matrix,\n",
    "            preprocess_function = preprocesser # optional\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR]\tjit.date_type_mutator\t\n",
      "<class '_ast.Module'> : \n",
      "  <class '_ast.Assign'> :  [output_hypervector___base_n_____n___2964e176 : __ARG__output_hypervector]\n",
      "  <class '_ast.For'> :  <RPT: F>\n",
      "    <class '_ast.Assign'> :  [output_hypervector___base_n_____n___2964e176 : __ARG__id_hvs*__ARG__level_hvs + output_hypervector___base_n_____n___2964e176]\n",
      "  <class '_ast.Assign'> :  [__ARG__output_hypervector : output_hypervector___base_n_____n___2964e176]\n",
      "\n",
      "\u001b[0m{'__n__': <class 'int'>, '__blockIdx_y__': <class 'int'>, '__base_n__': 'int', '__N__': <class 'int'>, '__blockDim_x__': <class 'int'>, '__F__': <class 'int'>, '__threadIdx_x__': <class 'int'>, 'F_PER_THREAD': <class 'int'>, 'sample_idx_in_stream': <class 'int'>, '__stream__': 'int', '__M__': <class 'int'>, '__f__': <class 'int'>, '__f_idx__': <class 'int'>, 'org_feature': <class 'float'>, 'input_features': 'np_float_array_type', 'cnv_feature': <class 'int'>, 'Q': <class 'int'>, '__shared_features__': 'np_float_array_type', '__d__': <class 'int'>, '__blockIdx_x__': <class 'int'>, '__D__': <class 'int'>, 'f': <class 'int'>, 'F': <class 'int'>, 'output_hypervector': 'hypermat_type', 'level_hvs': 'hypermat_type', 'id_hvs': 'hypermat_type', '__ARG__output_hypervector': 'float*', '__ARG__level_hvs': 'float*', '__ARG__id_hvs': 'float*', '__shared_features___f_fb10dfcf': <class 'float'>, 'level_hvs___shared_features___f_7add4eda': <class 'float'>, 'id_hvs_f_00177a23': <class 'float'>, 'output_hypervector___base_n_____n___2964e176': <class 'float'>, 'input_features_sample_idx_in_stream___f_idx___dc384242': <class 'float'>, '__shared_features_____f_idx___112c42af': <class 'float'>}\n",
      "Encode testing\t0.33038330078125\n"
     ]
    }
   ],
   "source": [
    "with hd.utils.timing(\"Encode testing\"):\n",
    "    hv_matrix_tst = hd.encode(\n",
    "            encoder, extra_args = (Q, level_hvs, id_hvs),\n",
    "            feature_matrix = feature_matrix_tst,\n",
    "            preprocess_function = preprocesser # optional\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the size for which encoding breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worked = []\n",
    "for i in range(feature_matrix_tst.shape[1], 0, -1):\n",
    "    print(i)\n",
    "    cropped_matrix = feature_matrix_tst[:2, :i]\n",
    "    worked.append(cropped_matrix.size * cropped_matrix.itemsize / (1024))# KB\n",
    "    try:\n",
    "        hv_matrix_tst = hd.encode(\n",
    "            encoder, extra_args = (Q, level_hvs, id_hvs),\n",
    "            feature_matrix = cropped_matrix,\n",
    "            preprocess_function = preprocesser # optional\n",
    "        )\n",
    "    except:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(worked )*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def single_pass(hv_matrix, labels, N, n_classes):\n",
    "    class_hvs = hd.hypermatrix(n_classes)\n",
    "\n",
    "    for idx in range(N):\n",
    "        class_hvs[labels[idx]] += hv_matrix[idx]\n",
    "\n",
    "    return class_hvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hd.utils.timing(\"Single pass\"):\n",
    "    class_hvs = single_pass(hv_matrix, labels, N, n_classes)\n",
    "    class_hvs.debug_print_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(labels, pred_labels):\n",
    "    n_correct = (pred_labels == labels).sum()\n",
    "    n_labels = len(labels)\n",
    "    print(n_correct, n_labels, n_correct / float(n_labels) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def retrain(class_hvs, hv_matrix, labels, N, n_classes):\n",
    "    search_results = hd.search(class_hvs, hv_matrix)\n",
    "\n",
    "    for idx in range(N):\n",
    "        if search_results[idx] != labels[idx]:\n",
    "            class_hvs[labels[idx]] += hv_matrix[idx]\n",
    "            class_hvs[search_results[idx]] -= hv_matrix[idx]\n",
    "\n",
    "    return class_hvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRAIN_ITERATIONS = 100\n",
    "SHOW_STEP_RESULT = True\n",
    "for it in range(RETRAIN_ITERATIONS):\n",
    "    with hd.utils.timing(\"Retrain itereation: %d\" % it):\n",
    "        class_hvs = retrain(class_hvs, hv_matrix, labels, N, n_classes)\n",
    "\n",
    "    if SHOW_STEP_RESULT and labels_tst is not None:\n",
    "        validate(labels_tst, hd.search(class_hvs, hv_matrix_tst).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hd.run\n",
    "def assoc_search(class_hvs, hv_matrix_tst):\n",
    "    ret = hd.search(class_hvs, hv_matrix_tst)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hd.utils.timing(\"Testing with class model\\n\"):\n",
    "    search_results = assoc_search(class_hvs, hv_matrix_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(labels_tst, search_results.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
